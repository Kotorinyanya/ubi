# Potato Monitor

[TOC]

## 文件夹

`spider`：旧爬虫程序，计划使用消息队列进行持久抓取，已放弃。

`new_spider`：爬虫程序，每次运行一次性抓取上次抓起以来的数据。

`NLP`：自然语言处理程序，包括权重预估模型与关键词句提取。

`web`：Web 程序，使用的 Flask 框架，包含前端与后端。

## 数据库定义

因为设计数据库时，计划中存在一些非核心功能，而部分功能在实现过程中被取消，所以部分字段略显冗余。

### 游戏表 `apps`

储存游戏的元数据。

####  重要字段

- `is_concerned`：为 `1` 即为需要系统分析的游戏。
- `crawled_at`：Unix 时间戳，此游戏上次采集数据的时间。

### 评测表 `reviews`

储存采集到的用户评测。

#### 重要字段

- `weight`：系统的权重预估模型给予的权重。
- `edited_at`：此评测最后被更新的时间，用作评测被修改时的追踪。

### 评测趋势表 `review_changes`

储存评测每日变动趋势，包括新增好差评、同条评论好差评之间的修改。

### 用户表 `users`

储存评论者的元数据。

#### 重要字段

- `weight`：系统的权重预估模型给予的权重。

### 分析结果表 `results`

储存每一个时间窗口中评论的分析结果。

#### 重要字段

- `window_length`：时间窗口的长度。
- `window_end_date`：时间窗口的结束日期。

## 使用

1. 导入根目录下的 `ubi.sql` 文件至数据库。

2. 安装 `new_spider`、`NLP`、`web` 中 `requirements.txt` 声明的依赖，建议使用 Python 3.6 的 virtualenv 环境。

3. 下载训练好的 [models.zip](TODO) 解压到 `NLP/models`

4. 数据的更新由 `spider` 目录中的脚本完成，每次运行会抓取上次抓取以来的数据。运行时可以命令行参数指定数据库连接参数，使用 `-h` 参数可查看详情。

   抓取步骤：

   1. 运行 `review_spider.py`，抓取上次抓取以来新增 / 发生改变的评测，以及用户的部分元数据。
   2. 运行 `user_spider.py`，抓取元数据不全的用户的其他元数据。

5. 数据采集后，需要对评测与用户的权重进行评估。在 `NLP` 目录中运行 `weight.py` 即可评估所有尚未评估权重的评测与用户。

6. 进行自然语言处理。在 `NLP ` 目录中指定参数运行 `process.py` 即可处理。

7. 在 `web` 目录中，运行 `app.py` 即可访问本机 `5000` 端口浏览网站（数据库在 `db.py` 中配置）。